---
title: S3
date: 2023-08-05 18:10:00 +/-0
categories: [aws-saa]
tags: [aws-saa, aws-s3]
---

## S3

S3는 유저들이 Object(파일)들을 "Bucket"에 저장할 수 있게 한다.

Bucket  
글로벌 unique name을 가져야 한다.(따라서 전 지역 그리고 전 계정에 대해 uniqueness를 가져야 함)  
하지만 Bucket 이름과 달리 실제론 Region level에서 정의된다.  
Objects  
Key - Value 형태로 Bucket에 저장된다.  
여기서 Key는 파일이 저장되는 path를 의미한다. 이는 Directories에 저장되는 것처럼 보이지만 실제로는 단지 Key값을 의미한다.
ex) s3://my-bucket/my_file.txt, s3://my-bucket/my_folder1/another_folder/my_file.txt  
따라서 Key는 prefix(Directory 이름들)+ object name으로 구성된다.  
Value는 최대 5TB까지 저장될 수 있으며 5GB 이상 데이터 저장 시 "multi-part upload"를 사용해야 한다.  
key-value 이외에는 Metadata, Tags, Version ID를 가진다.

### S3 Security

S3에는 User 쪽 그리고 Bucket 쪽 이렇게 2가지 쪽에서 Security를 설정할 수 있다.

- User-Based: IAM Policies로 S3에 접근 설정이 가능하다.
- Resource-Based: Bucket Policy로 Bucket wide한 rule을 설정 가능하다. 이외 Object Access Control List 그리고 Bucket Access Control List를 사용해 좀더 세밀한 접근 설정이 가능하다.
  따라서 IAM principal로 S3에 접근 가능한 경우는 IAM에서 ALLOW 또는 Resource에서 ALLOW를 한 경우 그리고 명시적인 DENY가 없을 때이다.

Bucket Policies  
JSON 형식으로 작성되며 이를 통해 Bucket에 대한 public access 그리고 upload되는 object의 암호화 강제 다른 계정에서의 접근 허가 등을 할 수 있다.  
아래와 같은 attr를 가진다.

- Resources: Buckets 또는 Objects를 의미한다.
- Effect: Allow/Deny
- Actions: Effect를 적용할 행동에 대한 API ex) "S3:GetObject"
- Principal: Policy를 적용할 account나 user

Block Public Access  
AWS에서는 S3에서 민감한 Data가 유출될 경우를 확실히 방지하고자 별도로 Bucket에 대한 public access를 방지할 수 있는 설정을 두었다. 이는 account level에 적용도 가능하며 Bucket Policy 상에서 public access를 허가하여도 override하여 불가능하게 해버린다.

### S3 Versioning

Bucket level에서 설정 가능하다.
이 기능을 키면 기존에 존재하던 Object의 version은 null이고 이후 부터 overwrite되는 object들은 versioning을 통해 저장한다.
이를 통해 의도하지 않는 삭제는 delete marked만 되어 되돌릴 수 있으며, 이전 version으로 쉽게 rollback이 가능하다.
만약 versioning을 사용하다 취소해도 이전 version들의 object들이 삭제되지 않는다.

### S3 Replication

source와 destination bucket 모두 versioning 설정을 켜야 사용할 수 있다.  
Cross-Region 또는 Same-Region에 대해 Bucket을 복제할 수 있다. 복사 과정은 async하게 진행된다.  
S3에 IAM permission을 부여해야 Bucket에 접근하여 복사가 이뤄질 수 있음을 유의한다.  
Cross-Region의 경우 low-latency access 또는 다른 계정으로의 데이터 복제 목적으로 사용  
Same-Region의 경우 기존 prod환경에 데이터를 test환경으로 복제 목적으로 사용될 수 있다.  
Replication이 설정되면 기존에 있던 데이터는 그대로 있고 새로 저장되는 데이터에 대한 복제만 이뤄지게 된다.  
만약 기존에 있는 데이터를 복제하고 싶다면 S3 Batch Replication을 사용한다.  
delete marked된 object에 대해서도 복제가 가능하다.(이는 선택 사항)  
Chaining을 지원하지 않아 1->2->3 순서로 replication을 구축해도 1->3으로 replication이 이뤄지지 않는다.

### S3 Storage Classes

Classes간 이동이 가능하며 S3 Lifecycle을 사용하거나 직접할 수 있음

- Standard
  - General Purpose: 자주 access되는 data를 보관할 때 사용하며 low latency와 high throughput을 가진다.
- Infrequent Access: 자주 access되지 않는 data를 보관할 때 사용하며, 필요할 때 빠르게 가져올 수 있다. standard보다 싸다.
  - S3 Standard-Infrequent Access: Disaster Recover용 백업 시 사용하기 적합
  - S3 One Zone-Infrequent Access: One Zone이기에 소실 위험이 좀더 큼. Secondary Backup으로 사용 적합하다.
- Glacier Storage: 낮은 가격에 object를 길게 보관할 때 사용되며, 가격은 크기와 가져올 때 발생한다.
  - S3 Glacier Instant Retrieval: milisecond로 보관되었던 data를 가져올 수 있음. 최소 90일까지 보관
  - " Flexible Retrieval: 1m~12hr까지 data를 가져올 때 소요될 수 있음(내부적으로 3개 tier로 분단위,3~5,5~12으로 구성됨) 최소 90일 보관
  - " Deep Archive-for long term storage: 12~48hr 소요되며 최소 180일까지 보관
- Intelligent-Tiering: Object가 접근되고 보관되는 것을 monitoring하다 알아서 사용량에 적합한 Tier로 보관해주는 기능 사용되는 Tier는 위 Standard 빼고 전부 가능

Moving between Storage Classes  
object들을 storage class간 이동할 수 있다.

Ex)  
Infrequent access의 경우 standard IA로  
빠른 접근이 필요하지 않는 Data를 보관하는 경우 Glacier 또는 Glacier Deep Archive으로 이동

### S3 Lifecycle Rules

특정 prefix 또는 tags에 적용할 수 있다.

- Transition actions: storage class간 object 이동에 대한 config
- Expiration actions: 저장된 object에 대한 만료(삭제) config로 versioning 사용 시 오래된 version의 object 삭제에 사용될 수 있다. 또한 중단된 Multi-part upload object도 삭제하는데 사용 가능

### S3 Analytics

object를 어떤 class로 transition할지 추천 해준다.  
Standard와 Standard IA에 대해서만 추천 가능

### Requester Pays

원래는 S3 Bucket owner가 보관 비용과 retrieval 비용 모두 부담하지만 해당 설정을 사용하면 owner가 보관 비용만을 내고 retrieval 비용은 requester가 낸다.
이를 위해서 request는 aws에 authenticated된 user여야 한다.

### S3 Event Notifications

Object에 대한 CRUD operation 등이 발생하면 여기에 대한 Event를 Target에 보낼 수 있다.
이러한 Event는 원하는 만큼 만들 수 있으며, Target에 Event를 보내기 위해서는 각 Target의 resource policy에서 S3에 대한 Event 허용을 설정해야 한다.
Target들:

- SNS
- SQS
- Lambda Functions
- EventBridge: Event에 대한 advanced filtering, multiple destinations, 저장, replay 등의 기능을 가진다. 이를 통해 18개 이상의 AWS Service에 event를 보낼 수 있다.

### S3 Baseline Performance

Bucket에 있는 각 prefix당 3500 PUT/COPY/POST/DELETE /s 또는 5500 GET/HEAD /s를 다룰 수 있다.  
따라서 만약 4개의 prefix가 있고 이에 대한 request가 균일하다면 최대 초당 22000의 GET/HEAD에 대한 req를 처리할 수 있는 것이다.  
다른 Performance 기능들:

- Multi-Part upload: 5GB 이상의 file부터 무조건 사용되며 upload를 병렬화하여 진행한다. 이를 통해 upload 과정이 빨라진다.
- S3 Transfer Acceleration: aws edge location에서 upload된 object를 빠르게 보내고 Client에서는 해당 Edge와 상호작용하며 object를 빠르게 받을 수 있다.
- Btye-Range Fetches: Object에 대한 특정 Byte만을 구간 별로 나눠서 동시에 요청해 Get request를 병렬화 할 수 있다. 또는 원하는 Object부분만 Byte크기만큼 가져올 수 있다. 이를 통해 GET과정을 더 빠르게 수행 가능

### S3 Select & Glacier Select

S3에서 SQL Select를 실행하는 Sever-side filtering을 통해 Object 내용들 중 원하는 데이터만을 빠르게 가져올 수 있다.

### S3 Batch Operations

Bulk operation을 수행하는 것이며 전 Object에 대한 수행 또는 unencrypted object들 전부 encrypt 등의 작업에서 수행 가능하다.
S3 Inventory를 통해 원하는 object들만을 list로 S3 Select에 보내면 원하는 Object들에만 Batch Operation을 수행 가능하다.
